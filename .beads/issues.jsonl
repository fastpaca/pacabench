{"id":"pacabench-16j","title":"UX Improvements","description":"Improve developer experience with comparison views and better output formatting.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-02T08:25:25.820877Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.820877Z"}
{"id":"pacabench-16j.1","title":"Compare performance across runs","description":"Users can run: pacabench compare run-1 run-2. Shows accuracy/latency/cost deltas.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:10.528903Z","created_by":"selund","updated_at":"2026-01-02T08:28:10.528903Z","dependencies":[{"issue_id":"pacabench-16j.1","depends_on_id":"pacabench-16j","type":"parent-child","created_at":"2026-01-02T08:28:10.531172Z","created_by":"selund"}]}
{"id":"pacabench-16j.2","title":"Export results to CSV","description":"Users can run: pacabench export --format csv. Spreadsheet-ready per-case results.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T08:28:10.556419Z","created_by":"selund","updated_at":"2026-01-02T08:28:10.556419Z","dependencies":[{"issue_id":"pacabench-16j.2","depends_on_id":"pacabench-16j","type":"parent-child","created_at":"2026-01-02T08:28:10.556886Z","created_by":"selund"}]}
{"id":"pacabench-3xf","title":"Publish to crates.io","description":"Prepare and publish pacabench-core and pacabench-cli to crates.io.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-02T08:25:25.740016Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.740016Z"}
{"id":"pacabench-3xf.1","title":"Prepare crate metadata for publishing","description":"Add proper Cargo.toml metadata: description, license, repository, keywords, categories.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:40.262591Z","created_by":"selund","updated_at":"2026-01-02T08:25:40.262591Z","dependencies":[{"issue_id":"pacabench-3xf.1","depends_on_id":"pacabench-3xf","type":"parent-child","created_at":"2026-01-02T08:25:40.264727Z","created_by":"selund"}]}
{"id":"pacabench-3xf.2","title":"Ensure API stability and semver compliance","description":"Review public API surface, ensure proper visibility, document breaking changes policy.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:40.289779Z","created_by":"selund","updated_at":"2026-01-02T08:25:40.289779Z","dependencies":[{"issue_id":"pacabench-3xf.2","depends_on_id":"pacabench-3xf","type":"parent-child","created_at":"2026-01-02T08:25:40.290245Z","created_by":"selund"}]}
{"id":"pacabench-7d5","title":"Multi-Provider Proxy Support","description":"Extend the metrics proxy to support Anthropic, Gemini, and other LLM providers.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-02T08:25:25.794798Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.794798Z"}
{"id":"pacabench-7d5.1","title":"Benchmark agents using Anthropic Claude","description":"Users can point agents at Claude API and get accurate metrics. x-api-key auth, parse input/output tokens.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:27:57.550394Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.550394Z","dependencies":[{"issue_id":"pacabench-7d5.1","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.552498Z","created_by":"selund"}]}
{"id":"pacabench-7d5.1.1","title":"Add Anthropic provider detection","description":"Detect api.anthropic.com in proxy target URL. Route to Anthropic-specific handling.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.647053Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.647053Z","dependencies":[{"issue_id":"pacabench-7d5.1.1","depends_on_id":"pacabench-7d5.1","type":"parent-child","created_at":"2026-01-02T08:28:41.649351Z","created_by":"selund"}]}
{"id":"pacabench-7d5.1.2","title":"Implement Anthropic auth and headers","description":"Use x-api-key header (not Bearer). Add required anthropic-version header.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.676041Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.676041Z","dependencies":[{"issue_id":"pacabench-7d5.1.2","depends_on_id":"pacabench-7d5.1","type":"parent-child","created_at":"2026-01-02T08:28:41.676572Z","created_by":"selund"}]}
{"id":"pacabench-7d5.1.3","title":"Parse Anthropic token usage format","description":"Extract input_tokens, output_tokens, cache_read/creation tokens. Map to normalized TokenUsage.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.703451Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.703451Z","dependencies":[{"issue_id":"pacabench-7d5.1.3","depends_on_id":"pacabench-7d5.1","type":"parent-child","created_at":"2026-01-02T08:28:41.703935Z","created_by":"selund"}]}
{"id":"pacabench-7d5.2","title":"Benchmark agents using Google Gemini","description":"Users can point agents at Gemini API and get accurate metrics. Parse usageMetadata, handle thinking tokens.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:27:57.579137Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.579137Z","dependencies":[{"issue_id":"pacabench-7d5.2","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.579601Z","created_by":"selund"}]}
{"id":"pacabench-7d5.2.1","title":"Add Gemini provider detection","description":"Detect generativelanguage.googleapis.com in proxy target URL.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.731207Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.731207Z","dependencies":[{"issue_id":"pacabench-7d5.2.1","depends_on_id":"pacabench-7d5.2","type":"parent-child","created_at":"2026-01-02T08:28:41.731691Z","created_by":"selund"}]}
{"id":"pacabench-7d5.2.2","title":"Implement Gemini auth","description":"Use x-goog-api-key header for authentication.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.758057Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.758057Z","dependencies":[{"issue_id":"pacabench-7d5.2.2","depends_on_id":"pacabench-7d5.2","type":"parent-child","created_at":"2026-01-02T08:28:41.758544Z","created_by":"selund"}]}
{"id":"pacabench-7d5.2.3","title":"Parse Gemini usageMetadata format","description":"Extract promptTokenCount, candidatesTokenCount, thoughtsTokenCount. Map to normalized TokenUsage.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.785885Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.785885Z","dependencies":[{"issue_id":"pacabench-7d5.2.3","depends_on_id":"pacabench-7d5.2","type":"parent-child","created_at":"2026-01-02T08:28:41.786371Z","created_by":"selund"}]}
{"id":"pacabench-7d5.3","title":"Benchmark agents using local models (Ollama)","description":"Users can benchmark against Ollama. Detect localhost:11434, handle no-auth.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:27:57.60332Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.60332Z","dependencies":[{"issue_id":"pacabench-7d5.3","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.603814Z","created_by":"selund"}]}
{"id":"pacabench-7d5.4","title":"Benchmark agents using any OpenAI-compatible API","description":"Groq, Mistral, Together, OpenRouter work seamlessly. Provider detection, verify token parsing.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:27:57.627627Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.627627Z","dependencies":[{"issue_id":"pacabench-7d5.4","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.628089Z","created_by":"selund"}]}
{"id":"pacabench-7d5.5","title":"Benchmark agents on Azure OpenAI","description":"Enterprise users can benchmark against Azure OpenAI. api-key header, deployment routing.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T08:27:57.652351Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.652351Z","dependencies":[{"issue_id":"pacabench-7d5.5","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.652826Z","created_by":"selund"}]}
{"id":"pacabench-7d5.6","title":"See estimated costs in benchmark results","description":"Users see cost breakdown in CLI output and exports. Pricing tables per model, cost from tokens.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:27:57.677269Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.677269Z","dependencies":[{"issue_id":"pacabench-7d5.6","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.677725Z","created_by":"selund"}]}
{"id":"pacabench-7d5.6.1","title":"Add model pricing configuration","description":"ModelPricing struct with input/output/cached rates. Ship defaults for GPT-4o, Claude, Gemini. User overrides.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:56.982064Z","created_by":"selund","updated_at":"2026-01-02T08:28:56.982064Z","dependencies":[{"issue_id":"pacabench-7d5.6.1","depends_on_id":"pacabench-7d5.6","type":"parent-child","created_at":"2026-01-02T08:28:56.984669Z","created_by":"selund"}]}
{"id":"pacabench-7d5.6.2","title":"Calculate and display costs","description":"Compute cost from tokens and pricing. Add to metrics. Show in CLI: total cost, avg per case.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:57.011208Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.011208Z","dependencies":[{"issue_id":"pacabench-7d5.6.2","depends_on_id":"pacabench-7d5.6","type":"parent-child","created_at":"2026-01-02T08:28:57.011706Z","created_by":"selund"}]}
{"id":"pacabench-7d5.6.3","title":"Export costs in JSON/Markdown/CSV","description":"Include cost fields in all export formats.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:57.038447Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.038447Z","dependencies":[{"issue_id":"pacabench-7d5.6.3","depends_on_id":"pacabench-7d5.6","type":"parent-child","created_at":"2026-01-02T08:28:57.038925Z","created_by":"selund"}]}
{"id":"pacabench-7j5","title":"Preset system infrastructure","description":"Core infrastructure for benchmark presets:\n\n1. **Preset registry** - Built-in configs that can be loaded via `--preset \u003cname\u003e`\n2. **HuggingFace datasets support** - Load parquet/arrow format properly (not just raw JSONL)\n3. **File attachment handling** - Auto-download files, include local paths in case payload\n4. **CLI integration** - `pacabench run --preset gaia --agent 'cmd'`\n\nPresets bundle: dataset source, split, input mappings, evaluator config, file handling.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-01-02T12:30:59.4792Z","created_by":"selund","updated_at":"2026-01-02T12:46:53.320223Z","closed_at":"2026-01-02T12:46:53.320223Z","close_reason":"Superseded by examples approach with Python prep scripts instead of built-in presets"}
{"id":"pacabench-b0c","title":"Improve LLM judge prompts for semantic equivalence","description":"Current judge prompt is too literal. Improve to handle:\n\n1. Numeric format variations ('17' vs '17000' when asking for 'thousand hours')\n2. Unit handling ('3 albums' vs '3')  \n3. Case/punctuation differences\n4. Semantic equivalence with context awareness\n\nConsider preset-specific judge prompts that understand the benchmark's expected answer format.\n\nCurrent prompt:\n```\nYou are evaluating if a model's answer is semantically equivalent to the expected answer.\nQuestion: {question}\nExpected Answer: {expected}\nModel's Answer: {output}\nRespond with ONLY YES or NO.\n```","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T12:31:42.108834Z","created_by":"selund","updated_at":"2026-01-02T12:31:42.108834Z","dependencies":[{"issue_id":"pacabench-b0c","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T12:32:13.894786Z","created_by":"selund"}]}
{"id":"pacabench-d2g","title":"Documentation \u0026 Onboarding","description":"Comprehensive docs, examples, and guides for integrating PacaBench.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-02T08:25:25.845792Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.845792Z"}
{"id":"pacabench-d2g.1","title":"Get started in under 5 minutes","description":"New users can install and run first benchmark quickly. Clear README, sample dataset.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:10.581129Z","created_by":"selund","updated_at":"2026-01-02T08:28:10.581129Z","dependencies":[{"issue_id":"pacabench-d2g.1","depends_on_id":"pacabench-d2g","type":"parent-child","created_at":"2026-01-02T08:28:10.581583Z","created_by":"selund"}]}
{"id":"pacabench-d2g.1.1","title":"Write quickstart README section","description":"Clear 5-step quickstart: install, init, configure, run, view. Copy-paste commands.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:57.14685Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.14685Z","dependencies":[{"issue_id":"pacabench-d2g.1.1","depends_on_id":"pacabench-d2g.1","type":"parent-child","created_at":"2026-01-02T08:28:57.147348Z","created_by":"selund"}]}
{"id":"pacabench-d2g.1.2","title":"Add pacabench init with starter config","description":"pacabench init creates pacabench.yaml with sensible defaults and comments.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:57.174079Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.174079Z","dependencies":[{"issue_id":"pacabench-d2g.1.2","depends_on_id":"pacabench-d2g.1","type":"parent-child","created_at":"2026-01-02T08:28:57.174565Z","created_by":"selund"}]}
{"id":"pacabench-d2g.1.3","title":"Include sample dataset for testing","description":"Ship or download tiny sample dataset (10 questions) to verify setup without API costs.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:57.199981Z","created_by":"selund","updated_at":"2026-01-02T12:48:40.379905Z","closed_at":"2026-01-02T12:48:40.379905Z","close_reason":"examples/smoke_test already provides a sample dataset for testing setup","dependencies":[{"issue_id":"pacabench-d2g.1.3","depends_on_id":"pacabench-d2g.1","type":"parent-child","created_at":"2026-01-02T08:28:57.200456Z","created_by":"selund"}]}
{"id":"pacabench-d2g.2","title":"Integrate PacaBench into existing agent project","description":"Integration guide, example configs for LangChain, AutoGPT, Claude Code.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:10.605946Z","created_by":"selund","updated_at":"2026-01-02T08:28:10.605946Z","dependencies":[{"issue_id":"pacabench-d2g.2","depends_on_id":"pacabench-d2g","type":"parent-child","created_at":"2026-01-02T08:28:10.606398Z","created_by":"selund"}]}
{"id":"pacabench-ehh","title":"Plug-and-Play Benchmark Support","description":"Make PacaBench the definitive way to run popular agent benchmarks locally and in CI.\n\nApproach: **Examples** - each benchmark gets its own examples/ directory with:\n- Python prep script for dataset download/formatting\n- pacabench.yaml configuration  \n- Sample agent implementation\n- README with setup instructions\n\nPattern established in examples/gaia - new benchmarks follow the same structure.\n\nThe agent wrapper (stdin/stdout JSONL) remains the user's responsibility - pacabench is a harness, not an agent framework.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-02T08:25:25.767302Z","created_by":"selund","updated_at":"2026-01-02T12:47:47.471749Z"}
{"id":"pacabench-ehh.1","title":"Run GAIA benchmark locally","description":"Users can run: pacabench run --preset gaia. HuggingFace dataset with file attachments, exact_match evaluator, level filtering.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:51.323528Z","created_by":"selund","updated_at":"2026-01-02T12:47:06.930647Z","closed_at":"2026-01-02T12:47:06.930647Z","close_reason":"Completed - GAIA example in examples/gaia with smolagent integration","dependencies":[{"issue_id":"pacabench-ehh.1","depends_on_id":"pacabench-7j5","type":"blocks","created_at":"2026-01-02T12:31:11.322278Z","created_by":"selund"}]}
{"id":"pacabench-ehh.1.1","title":"Add HuggingFace dataset file attachment support","description":"Part of preset infrastructure. Auto-download file attachments from HuggingFace datasets and include local paths in case payload.\n\nCase sent to agent should include:\n```json\n{\"input\": \"Question...\", \"file_path\": \"/local/cache/file.xlsx\", \"file_name\": \"data.xlsx\"}\n```\n\nLearned from GAIA experiment: files are referenced via `file_path` field in HF dataset, need `hf_hub_download()` to get local copies.","status":"closed","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:20.585745Z","created_by":"selund","updated_at":"2026-01-02T12:47:00.9538Z","closed_at":"2026-01-02T12:47:00.9538Z","close_reason":"Completed via examples/gaia with Python prep script approach","dependencies":[{"issue_id":"pacabench-ehh.1.1","depends_on_id":"pacabench-ehh.1","type":"parent-child","created_at":"2026-01-02T08:28:20.587667Z","created_by":"selund"}]}
{"id":"pacabench-ehh.1.2","title":"Create GAIA preset configuration","description":"Create GAIA preset configuration:\n\n```yaml\n# Built-in preset for GAIA\nname: gaia\ndataset:\n  source: huggingface:gaia-benchmark/GAIA\n  config: 2023_all\n  split: validation\n  input_map:\n    input: Question\n    expected: \"Final answer\"\n  files:\n    path_field: file_path\n    name_field: file_name\nevaluator:\n  type: llm_judge  # or exact_match with normalization\n  model: gpt-4o-mini\noptions:\n  level: 1|2|3|all  # Filter by difficulty\n```\n\nLearned: LLM judge works better than exact match due to format variations (e.g., '17' vs '17000' for 'thousand hours').","status":"closed","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:20.614443Z","created_by":"selund","updated_at":"2026-01-02T12:47:00.955271Z","closed_at":"2026-01-02T12:47:00.955271Z","close_reason":"Completed via examples/gaia with Python prep script approach","dependencies":[{"issue_id":"pacabench-ehh.1.2","depends_on_id":"pacabench-ehh.1","type":"parent-child","created_at":"2026-01-02T08:28:20.614947Z","created_by":"selund"}]}
{"id":"pacabench-ehh.1.3","title":"Add answer normalization for exact match","description":"Lowercase, strip whitespace, handle numeric formats. Match official leaderboard methodology.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:20.639712Z","created_by":"selund","updated_at":"2026-01-02T12:47:00.956366Z","closed_at":"2026-01-02T12:47:00.956366Z","close_reason":"Completed via examples/gaia with Python prep script approach","dependencies":[{"issue_id":"pacabench-ehh.1.3","depends_on_id":"pacabench-ehh.1","type":"parent-child","created_at":"2026-01-02T08:28:20.640192Z","created_by":"selund"}]}
{"id":"pacabench-ehh.2","title":"Run MMLU benchmark locally","description":"Add an MMLU benchmark example to examples/mmlu. Follows the same pattern as GAIA: Python prep script for dataset download, pacabench.yaml for config. Multiple choice evaluator.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:51.351032Z","created_by":"selund","updated_at":"2026-01-02T12:47:26.989407Z","dependencies":[{"issue_id":"pacabench-ehh.2","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.351512Z","created_by":"selund"}]}
{"id":"pacabench-ehh.2.1","title":"Create MMLU example directory","description":"Create examples/mmlu with prep script and pacabench.yaml, following GAIA pattern","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:31.718975Z","created_by":"selund","updated_at":"2026-01-02T12:47:35.91336Z","dependencies":[{"issue_id":"pacabench-ehh.2.1","depends_on_id":"pacabench-ehh.2","type":"parent-child","created_at":"2026-01-02T08:28:31.721105Z","created_by":"selund"}]}
{"id":"pacabench-ehh.2.2","title":"Add per-subject accuracy reporting","description":"MMLU has 57 subjects. Report accuracy breakdown by subject and category (STEM, humanities, etc).","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:31.746321Z","created_by":"selund","updated_at":"2026-01-02T08:28:31.746321Z","dependencies":[{"issue_id":"pacabench-ehh.2.2","depends_on_id":"pacabench-ehh.2","type":"parent-child","created_at":"2026-01-02T08:28:31.746824Z","created_by":"selund"}]}
{"id":"pacabench-ehh.3","title":"Run HumanEval benchmark locally","description":"Add a HumanEval benchmark example to examples/humaneval. Follows the same pattern as GAIA: Python prep script for dataset download, pacabench.yaml for config. Requires sandboxed Python execution and pass@k metrics.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:51.376321Z","created_by":"selund","updated_at":"2026-01-02T12:47:27.93814Z","dependencies":[{"issue_id":"pacabench-ehh.3","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.376826Z","created_by":"selund"}]}
{"id":"pacabench-ehh.3.1","title":"Add sandboxed Python code execution evaluator","description":"New evaluator type: code_execution. Run Python against test suite with resource limits.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:31.772347Z","created_by":"selund","updated_at":"2026-01-02T08:28:31.772347Z","dependencies":[{"issue_id":"pacabench-ehh.3.1","depends_on_id":"pacabench-ehh.3","type":"parent-child","created_at":"2026-01-02T08:28:31.772856Z","created_by":"selund"}]}
{"id":"pacabench-ehh.3.2","title":"Add pass@k sampling and metrics","description":"Generate k completions per problem, calculate pass@k rate. Use unbiased estimator from HumanEval paper.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:31.798985Z","created_by":"selund","updated_at":"2026-01-02T08:28:31.798985Z","dependencies":[{"issue_id":"pacabench-ehh.3.2","depends_on_id":"pacabench-ehh.3","type":"parent-child","created_at":"2026-01-02T08:28:31.799446Z","created_by":"selund"}]}
{"id":"pacabench-ehh.3.3","title":"Create HumanEval example directory","description":"Create examples/humaneval with prep script and pacabench.yaml, following GAIA pattern","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:31.825186Z","created_by":"selund","updated_at":"2026-01-02T12:47:37.023433Z","dependencies":[{"issue_id":"pacabench-ehh.3.3","depends_on_id":"pacabench-ehh.3","type":"parent-child","created_at":"2026-01-02T08:28:31.82575Z","created_by":"selund"}]}
{"id":"pacabench-ehh.4","title":"Run SWE-bench Lite locally","description":"Add a SWE-bench Lite example to examples/swe-bench-lite. Follows GAIA pattern with prep script. Will need Docker sandbox for code execution.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:51.401043Z","created_by":"selund","updated_at":"2026-01-02T12:48:15.69964Z","dependencies":[{"issue_id":"pacabench-ehh.4","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.401496Z","created_by":"selund"}]}
{"id":"pacabench-ehh.5","title":"Run SimpleQA benchmark locally","description":"Add a SimpleQA example to examples/simpleqa. Follows GAIA pattern with prep script and LLM judge evaluator.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:51.426091Z","created_by":"selund","updated_at":"2026-01-02T12:48:16.791548Z","dependencies":[{"issue_id":"pacabench-ehh.5","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.426548Z","created_by":"selund"}]}
{"id":"pacabench-ehh.6","title":"Run GPQA benchmark locally","description":"Add a GPQA example to examples/gpqa. Follows GAIA pattern with prep script. Multiple choice evaluator.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:51.450541Z","created_by":"selund","updated_at":"2026-01-02T12:48:20.083239Z","dependencies":[{"issue_id":"pacabench-ehh.6","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.450987Z","created_by":"selund"}]}
{"id":"pacabench-ehh.7","title":"Run function-calling benchmarks (BFCL)","description":"Add a Berkeley Function Calling Leaderboard example to examples/bfcl. Follows GAIA pattern with prep script.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:51.474748Z","created_by":"selund","updated_at":"2026-01-02T12:48:21.479884Z","dependencies":[{"issue_id":"pacabench-ehh.7","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.475198Z","created_by":"selund"}]}
{"id":"pacabench-mls","title":"DevOps \u0026 CI/CD","description":"Set up GitHub Actions, automated testing, release workflows, and quality gates.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-02T08:25:25.711289Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.711289Z"}
{"id":"pacabench-mls.1","title":"Set up GitHub Actions CI","description":"Workflow for fmt, clippy, tests on every PR. Matrix testing for stable/nightly Rust.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:33.500085Z","created_by":"selund","updated_at":"2026-01-02T08:25:33.500085Z","dependencies":[{"issue_id":"pacabench-mls.1","depends_on_id":"pacabench-mls","type":"parent-child","created_at":"2026-01-02T08:25:33.501891Z","created_by":"selund"}]}
{"id":"pacabench-mls.2","title":"Add release automation workflow","description":"Automated releases with changelog generation and crates.io publishing.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:33.531116Z","created_by":"selund","updated_at":"2026-01-02T08:25:33.531116Z","dependencies":[{"issue_id":"pacabench-mls.2","depends_on_id":"pacabench-mls","type":"parent-child","created_at":"2026-01-02T08:25:33.531661Z","created_by":"selund"}]}
{"id":"pacabench-mls.3","title":"Run benchmarks in CI/CD","description":"Users can add PacaBench to GitHub Actions with pass/fail thresholds and JSON output.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:33.560098Z","created_by":"selund","updated_at":"2026-01-02T08:25:33.560098Z","dependencies":[{"issue_id":"pacabench-mls.3","depends_on_id":"pacabench-mls","type":"parent-child","created_at":"2026-01-02T08:25:33.560651Z","created_by":"selund"}]}
{"id":"pacabench-mls.3.1","title":"Add --threshold flag for pass/fail exit codes","description":"pacabench run --threshold 0.8 exits with code 1 if accuracy \u003c 80%. Enables CI gates.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:57.066175Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.066175Z","dependencies":[{"issue_id":"pacabench-mls.3.1","depends_on_id":"pacabench-mls.3","type":"parent-child","created_at":"2026-01-02T08:28:57.066657Z","created_by":"selund"}]}
{"id":"pacabench-mls.3.2","title":"Create GitHub Actions workflow example","description":"Example .github/workflows/benchmark.yml that runs pacabench on PR, caches datasets.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:57.092526Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.092526Z","dependencies":[{"issue_id":"pacabench-mls.3.2","depends_on_id":"pacabench-mls.3","type":"parent-child","created_at":"2026-01-02T08:28:57.093019Z","created_by":"selund"}]}
{"id":"pacabench-mls.3.3","title":"Add JSON output mode for CI parsing","description":"pacabench run --output json prints structured results to stdout.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:57.120194Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.120194Z","dependencies":[{"issue_id":"pacabench-mls.3.3","depends_on_id":"pacabench-mls.3","type":"parent-child","created_at":"2026-01-02T08:28:57.120643Z","created_by":"selund"}]}
