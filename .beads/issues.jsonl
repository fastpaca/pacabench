{"id":"pacabench-16j","title":"UX Improvements","description":"Improve developer experience with comparison views and better output formatting.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-02T08:25:25.820877Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.820877Z"}
{"id":"pacabench-16j.1","title":"Compare performance across runs","description":"Users can run: pacabench compare run-1 run-2. Shows accuracy/latency/cost deltas.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:10.528903Z","created_by":"selund","updated_at":"2026-01-02T08:28:10.528903Z","dependencies":[{"issue_id":"pacabench-16j.1","depends_on_id":"pacabench-16j","type":"parent-child","created_at":"2026-01-02T08:28:10.531172Z","created_by":"selund"}]}
{"id":"pacabench-16j.2","title":"Export results to CSV","description":"Users can run: pacabench export --format csv. Spreadsheet-ready per-case results.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T08:28:10.556419Z","created_by":"selund","updated_at":"2026-01-02T08:28:10.556419Z","dependencies":[{"issue_id":"pacabench-16j.2","depends_on_id":"pacabench-16j","type":"parent-child","created_at":"2026-01-02T08:28:10.556886Z","created_by":"selund"}]}
{"id":"pacabench-3xf","title":"Publish to crates.io","description":"Prepare and publish pacabench-core and pacabench-cli to crates.io.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-02T08:25:25.740016Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.740016Z"}
{"id":"pacabench-3xf.1","title":"Prepare crate metadata for publishing","description":"Add proper Cargo.toml metadata: description, license, repository, keywords, categories.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:40.262591Z","created_by":"selund","updated_at":"2026-01-02T08:25:40.262591Z","dependencies":[{"issue_id":"pacabench-3xf.1","depends_on_id":"pacabench-3xf","type":"parent-child","created_at":"2026-01-02T08:25:40.264727Z","created_by":"selund"}]}
{"id":"pacabench-3xf.2","title":"Ensure API stability and semver compliance","description":"Review public API surface, ensure proper visibility, document breaking changes policy.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:40.289779Z","created_by":"selund","updated_at":"2026-01-02T08:25:40.289779Z","dependencies":[{"issue_id":"pacabench-3xf.2","depends_on_id":"pacabench-3xf","type":"parent-child","created_at":"2026-01-02T08:25:40.290245Z","created_by":"selund"}]}
{"id":"pacabench-7d5","title":"Multi-Provider Proxy Support","description":"Extend the metrics proxy to support Anthropic, Gemini, and other LLM providers.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-02T08:25:25.794798Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.794798Z"}
{"id":"pacabench-7d5.1","title":"Benchmark agents using Anthropic Claude","description":"Users can point agents at Claude API and get accurate metrics. x-api-key auth, parse input/output tokens.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:27:57.550394Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.550394Z","dependencies":[{"issue_id":"pacabench-7d5.1","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.552498Z","created_by":"selund"}]}
{"id":"pacabench-7d5.1.1","title":"Add Anthropic provider detection","description":"Detect api.anthropic.com in proxy target URL. Route to Anthropic-specific handling.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.647053Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.647053Z","dependencies":[{"issue_id":"pacabench-7d5.1.1","depends_on_id":"pacabench-7d5.1","type":"parent-child","created_at":"2026-01-02T08:28:41.649351Z","created_by":"selund"}]}
{"id":"pacabench-7d5.1.2","title":"Implement Anthropic auth and headers","description":"Use x-api-key header (not Bearer). Add required anthropic-version header.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.676041Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.676041Z","dependencies":[{"issue_id":"pacabench-7d5.1.2","depends_on_id":"pacabench-7d5.1","type":"parent-child","created_at":"2026-01-02T08:28:41.676572Z","created_by":"selund"}]}
{"id":"pacabench-7d5.1.3","title":"Parse Anthropic token usage format","description":"Extract input_tokens, output_tokens, cache_read/creation tokens. Map to normalized TokenUsage.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.703451Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.703451Z","dependencies":[{"issue_id":"pacabench-7d5.1.3","depends_on_id":"pacabench-7d5.1","type":"parent-child","created_at":"2026-01-02T08:28:41.703935Z","created_by":"selund"}]}
{"id":"pacabench-7d5.2","title":"Benchmark agents using Google Gemini","description":"Users can point agents at Gemini API and get accurate metrics. Parse usageMetadata, handle thinking tokens.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:27:57.579137Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.579137Z","dependencies":[{"issue_id":"pacabench-7d5.2","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.579601Z","created_by":"selund"}]}
{"id":"pacabench-7d5.2.1","title":"Add Gemini provider detection","description":"Detect generativelanguage.googleapis.com in proxy target URL.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.731207Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.731207Z","dependencies":[{"issue_id":"pacabench-7d5.2.1","depends_on_id":"pacabench-7d5.2","type":"parent-child","created_at":"2026-01-02T08:28:41.731691Z","created_by":"selund"}]}
{"id":"pacabench-7d5.2.2","title":"Implement Gemini auth","description":"Use x-goog-api-key header for authentication.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.758057Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.758057Z","dependencies":[{"issue_id":"pacabench-7d5.2.2","depends_on_id":"pacabench-7d5.2","type":"parent-child","created_at":"2026-01-02T08:28:41.758544Z","created_by":"selund"}]}
{"id":"pacabench-7d5.2.3","title":"Parse Gemini usageMetadata format","description":"Extract promptTokenCount, candidatesTokenCount, thoughtsTokenCount. Map to normalized TokenUsage.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:41.785885Z","created_by":"selund","updated_at":"2026-01-02T08:28:41.785885Z","dependencies":[{"issue_id":"pacabench-7d5.2.3","depends_on_id":"pacabench-7d5.2","type":"parent-child","created_at":"2026-01-02T08:28:41.786371Z","created_by":"selund"}]}
{"id":"pacabench-7d5.3","title":"Benchmark agents using local models (Ollama)","description":"Users can benchmark against Ollama. Detect localhost:11434, handle no-auth.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:27:57.60332Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.60332Z","dependencies":[{"issue_id":"pacabench-7d5.3","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.603814Z","created_by":"selund"}]}
{"id":"pacabench-7d5.4","title":"Benchmark agents using any OpenAI-compatible API","description":"Groq, Mistral, Together, OpenRouter work seamlessly. Provider detection, verify token parsing.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:27:57.627627Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.627627Z","dependencies":[{"issue_id":"pacabench-7d5.4","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.628089Z","created_by":"selund"}]}
{"id":"pacabench-7d5.5","title":"Benchmark agents on Azure OpenAI","description":"Enterprise users can benchmark against Azure OpenAI. api-key header, deployment routing.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-02T08:27:57.652351Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.652351Z","dependencies":[{"issue_id":"pacabench-7d5.5","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.652826Z","created_by":"selund"}]}
{"id":"pacabench-7d5.6","title":"See estimated costs in benchmark results","description":"Users see cost breakdown in CLI output and exports. Pricing tables per model, cost from tokens.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:27:57.677269Z","created_by":"selund","updated_at":"2026-01-02T08:27:57.677269Z","dependencies":[{"issue_id":"pacabench-7d5.6","depends_on_id":"pacabench-7d5","type":"parent-child","created_at":"2026-01-02T08:27:57.677725Z","created_by":"selund"}]}
{"id":"pacabench-7d5.6.1","title":"Add model pricing configuration","description":"ModelPricing struct with input/output/cached rates. Ship defaults for GPT-4o, Claude, Gemini. User overrides.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:56.982064Z","created_by":"selund","updated_at":"2026-01-02T08:28:56.982064Z","dependencies":[{"issue_id":"pacabench-7d5.6.1","depends_on_id":"pacabench-7d5.6","type":"parent-child","created_at":"2026-01-02T08:28:56.984669Z","created_by":"selund"}]}
{"id":"pacabench-7d5.6.2","title":"Calculate and display costs","description":"Compute cost from tokens and pricing. Add to metrics. Show in CLI: total cost, avg per case.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:57.011208Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.011208Z","dependencies":[{"issue_id":"pacabench-7d5.6.2","depends_on_id":"pacabench-7d5.6","type":"parent-child","created_at":"2026-01-02T08:28:57.011706Z","created_by":"selund"}]}
{"id":"pacabench-7d5.6.3","title":"Export costs in JSON/Markdown/CSV","description":"Include cost fields in all export formats.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:57.038447Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.038447Z","dependencies":[{"issue_id":"pacabench-7d5.6.3","depends_on_id":"pacabench-7d5.6","type":"parent-child","created_at":"2026-01-02T08:28:57.038925Z","created_by":"selund"}]}
{"id":"pacabench-7j5","title":"Preset system infrastructure","description":"Core infrastructure for benchmark presets:\n\n1. **Preset registry** - Built-in configs that can be loaded via `--preset \u003cname\u003e`\n2. **HuggingFace datasets support** - Load parquet/arrow format properly (not just raw JSONL)\n3. **File attachment handling** - Auto-download files, include local paths in case payload\n4. **CLI integration** - `pacabench run --preset gaia --agent 'cmd'`\n\nPresets bundle: dataset source, split, input mappings, evaluator config, file handling.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T12:30:59.4792Z","created_by":"selund","updated_at":"2026-01-02T12:30:59.4792Z"}
{"id":"pacabench-b0c","title":"Improve LLM judge prompts for semantic equivalence","description":"Current judge prompt is too literal. Improve to handle:\n\n1. Numeric format variations ('17' vs '17000' when asking for 'thousand hours')\n2. Unit handling ('3 albums' vs '3')  \n3. Case/punctuation differences\n4. Semantic equivalence with context awareness\n\nConsider preset-specific judge prompts that understand the benchmark's expected answer format.\n\nCurrent prompt:\n```\nYou are evaluating if a model's answer is semantically equivalent to the expected answer.\nQuestion: {question}\nExpected Answer: {expected}\nModel's Answer: {output}\nRespond with ONLY YES or NO.\n```","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T12:31:42.108834Z","created_by":"selund","updated_at":"2026-01-02T12:31:42.108834Z","dependencies":[{"issue_id":"pacabench-b0c","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T12:32:13.894786Z","created_by":"selund"}]}
{"id":"pacabench-d2g","title":"Documentation \u0026 Onboarding","description":"Comprehensive docs, examples, and guides for integrating PacaBench.","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-02T08:25:25.845792Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.845792Z"}
{"id":"pacabench-d2g.1","title":"Get started in under 5 minutes","description":"New users can install and run first benchmark quickly. Clear README, sample dataset.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:10.581129Z","created_by":"selund","updated_at":"2026-01-02T08:28:10.581129Z","dependencies":[{"issue_id":"pacabench-d2g.1","depends_on_id":"pacabench-d2g","type":"parent-child","created_at":"2026-01-02T08:28:10.581583Z","created_by":"selund"}]}
{"id":"pacabench-d2g.1.1","title":"Write quickstart README section","description":"Clear 5-step quickstart: install, init, configure, run, view. Copy-paste commands.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:57.14685Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.14685Z","dependencies":[{"issue_id":"pacabench-d2g.1.1","depends_on_id":"pacabench-d2g.1","type":"parent-child","created_at":"2026-01-02T08:28:57.147348Z","created_by":"selund"}]}
{"id":"pacabench-d2g.1.2","title":"Add pacabench init with starter config","description":"pacabench init creates pacabench.yaml with sensible defaults and comments.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:57.174079Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.174079Z","dependencies":[{"issue_id":"pacabench-d2g.1.2","depends_on_id":"pacabench-d2g.1","type":"parent-child","created_at":"2026-01-02T08:28:57.174565Z","created_by":"selund"}]}
{"id":"pacabench-d2g.1.3","title":"Include sample dataset for testing","description":"Ship or download tiny sample dataset (10 questions) to verify setup without API costs.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:57.199981Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.199981Z","dependencies":[{"issue_id":"pacabench-d2g.1.3","depends_on_id":"pacabench-d2g.1","type":"parent-child","created_at":"2026-01-02T08:28:57.200456Z","created_by":"selund"}]}
{"id":"pacabench-d2g.2","title":"Integrate PacaBench into existing agent project","description":"Integration guide, example configs for LangChain, AutoGPT, Claude Code.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:10.605946Z","created_by":"selund","updated_at":"2026-01-02T08:28:10.605946Z","dependencies":[{"issue_id":"pacabench-d2g.2","depends_on_id":"pacabench-d2g","type":"parent-child","created_at":"2026-01-02T08:28:10.606398Z","created_by":"selund"}]}
{"id":"pacabench-ehh","title":"Plug-and-Play Benchmark Support","description":"Make PacaBench the definitive way to run popular agent benchmarks locally and in CI.\n\nCore feature: **Presets** - built-in configurations for standard benchmarks that handle:\n- Dataset loading (HuggingFace, with proper parquet support)\n- File attachment downloads (auto-download, provide local paths)\n- Evaluator configuration (exact match, LLM judge with tuned prompts)\n- Input/output field mappings\n\nUser experience: `pacabench run --preset gaia --agent 'python my_agent.py'`\n\nThe agent wrapper (stdin/stdout JSONL) remains the user's responsibility - pacabench is a harness, not an agent framework.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-02T08:25:25.767302Z","created_by":"selund","updated_at":"2026-01-02T12:30:49.395997Z"}
{"id":"pacabench-ehh.1","title":"Run GAIA benchmark locally","description":"Users can run: pacabench run --preset gaia. HuggingFace dataset with file attachments, exact_match evaluator, level filtering.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:51.323528Z","created_by":"selund","updated_at":"2026-01-02T08:25:51.323528Z","dependencies":[{"issue_id":"pacabench-ehh.1","depends_on_id":"pacabench-7j5","type":"blocks","created_at":"2026-01-02T12:31:11.322278Z","created_by":"selund"}]}
{"id":"pacabench-ehh.1.1","title":"Add HuggingFace dataset file attachment support","description":"Part of preset infrastructure. Auto-download file attachments from HuggingFace datasets and include local paths in case payload.\n\nCase sent to agent should include:\n```json\n{\"input\": \"Question...\", \"file_path\": \"/local/cache/file.xlsx\", \"file_name\": \"data.xlsx\"}\n```\n\nLearned from GAIA experiment: files are referenced via `file_path` field in HF dataset, need `hf_hub_download()` to get local copies.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:20.585745Z","created_by":"selund","updated_at":"2026-01-02T12:31:21.586111Z","dependencies":[{"issue_id":"pacabench-ehh.1.1","depends_on_id":"pacabench-ehh.1","type":"parent-child","created_at":"2026-01-02T08:28:20.587667Z","created_by":"selund"}]}
{"id":"pacabench-ehh.1.2","title":"Create GAIA preset configuration","description":"Create GAIA preset configuration:\n\n```yaml\n# Built-in preset for GAIA\nname: gaia\ndataset:\n  source: huggingface:gaia-benchmark/GAIA\n  config: 2023_all\n  split: validation\n  input_map:\n    input: Question\n    expected: \"Final answer\"\n  files:\n    path_field: file_path\n    name_field: file_name\nevaluator:\n  type: llm_judge  # or exact_match with normalization\n  model: gpt-4o-mini\noptions:\n  level: 1|2|3|all  # Filter by difficulty\n```\n\nLearned: LLM judge works better than exact match due to format variations (e.g., '17' vs '17000' for 'thousand hours').","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:20.614443Z","created_by":"selund","updated_at":"2026-01-02T12:31:31.516351Z","dependencies":[{"issue_id":"pacabench-ehh.1.2","depends_on_id":"pacabench-ehh.1","type":"parent-child","created_at":"2026-01-02T08:28:20.614947Z","created_by":"selund"}]}
{"id":"pacabench-ehh.1.3","title":"Add answer normalization for exact match","description":"Lowercase, strip whitespace, handle numeric formats. Match official leaderboard methodology.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:20.639712Z","created_by":"selund","updated_at":"2026-01-02T08:28:20.639712Z","dependencies":[{"issue_id":"pacabench-ehh.1.3","depends_on_id":"pacabench-ehh.1","type":"parent-child","created_at":"2026-01-02T08:28:20.640192Z","created_by":"selund"}]}
{"id":"pacabench-ehh.2","title":"Run MMLU benchmark locally","description":"Users can run: pacabench run --preset mmlu. Multiple choice evaluator, per-subject accuracy reporting.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:51.351032Z","created_by":"selund","updated_at":"2026-01-02T08:25:51.351032Z","dependencies":[{"issue_id":"pacabench-ehh.2","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.351512Z","created_by":"selund"}]}
{"id":"pacabench-ehh.2.1","title":"Create MMLU preset configuration","description":"Auto-configure dataset (cais/mmlu), multiple_choice evaluator. Format questions with A/B/C/D choices.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:31.718975Z","created_by":"selund","updated_at":"2026-01-02T08:28:31.718975Z","dependencies":[{"issue_id":"pacabench-ehh.2.1","depends_on_id":"pacabench-ehh.2","type":"parent-child","created_at":"2026-01-02T08:28:31.721105Z","created_by":"selund"}]}
{"id":"pacabench-ehh.2.2","title":"Add per-subject accuracy reporting","description":"MMLU has 57 subjects. Report accuracy breakdown by subject and category (STEM, humanities, etc).","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:31.746321Z","created_by":"selund","updated_at":"2026-01-02T08:28:31.746321Z","dependencies":[{"issue_id":"pacabench-ehh.2.2","depends_on_id":"pacabench-ehh.2","type":"parent-child","created_at":"2026-01-02T08:28:31.746824Z","created_by":"selund"}]}
{"id":"pacabench-ehh.3","title":"Run HumanEval benchmark locally","description":"Users can run: pacabench run --preset humaneval. Sandboxed Python execution, pass@k metrics.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:51.376321Z","created_by":"selund","updated_at":"2026-01-02T08:25:51.376321Z","dependencies":[{"issue_id":"pacabench-ehh.3","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.376826Z","created_by":"selund"}]}
{"id":"pacabench-ehh.3.1","title":"Add sandboxed Python code execution evaluator","description":"New evaluator type: code_execution. Run Python against test suite with resource limits.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:31.772347Z","created_by":"selund","updated_at":"2026-01-02T08:28:31.772347Z","dependencies":[{"issue_id":"pacabench-ehh.3.1","depends_on_id":"pacabench-ehh.3","type":"parent-child","created_at":"2026-01-02T08:28:31.772856Z","created_by":"selund"}]}
{"id":"pacabench-ehh.3.2","title":"Add pass@k sampling and metrics","description":"Generate k completions per problem, calculate pass@k rate. Use unbiased estimator from HumanEval paper.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:31.798985Z","created_by":"selund","updated_at":"2026-01-02T08:28:31.798985Z","dependencies":[{"issue_id":"pacabench-ehh.3.2","depends_on_id":"pacabench-ehh.3","type":"parent-child","created_at":"2026-01-02T08:28:31.799446Z","created_by":"selund"}]}
{"id":"pacabench-ehh.3.3","title":"Create HumanEval preset configuration","description":"Auto-configure dataset (openai/humaneval), code_execution evaluator, completion-style prompting.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:31.825186Z","created_by":"selund","updated_at":"2026-01-02T08:28:31.825186Z","dependencies":[{"issue_id":"pacabench-ehh.3.3","depends_on_id":"pacabench-ehh.3","type":"parent-child","created_at":"2026-01-02T08:28:31.82575Z","created_by":"selund"}]}
{"id":"pacabench-ehh.4","title":"Run SWE-bench Lite locally","description":"Users can run: pacabench run --preset swebench-lite. Docker integration, shell out to official harness.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:51.401043Z","created_by":"selund","updated_at":"2026-01-02T08:25:51.401043Z","dependencies":[{"issue_id":"pacabench-ehh.4","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.401496Z","created_by":"selund"}]}
{"id":"pacabench-ehh.5","title":"Run SimpleQA benchmark locally","description":"Users can run: pacabench run --preset simpleqa. Exact match with normalization, precision metrics.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:51.426091Z","created_by":"selund","updated_at":"2026-01-02T08:25:51.426091Z","dependencies":[{"issue_id":"pacabench-ehh.5","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.426548Z","created_by":"selund"}]}
{"id":"pacabench-ehh.6","title":"Run GPQA benchmark locally","description":"Users can run: pacabench run --preset gpqa. Multiple choice, 448 graduate-level science questions.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:51.450541Z","created_by":"selund","updated_at":"2026-01-02T08:25:51.450541Z","dependencies":[{"issue_id":"pacabench-ehh.6","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.450987Z","created_by":"selund"}]}
{"id":"pacabench-ehh.7","title":"Run function-calling benchmarks (BFCL)","description":"Users can run: pacabench run --preset bfcl. AST-based or LLM judge for function call validation.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:51.474748Z","created_by":"selund","updated_at":"2026-01-02T08:25:51.474748Z","dependencies":[{"issue_id":"pacabench-ehh.7","depends_on_id":"pacabench-ehh","type":"parent-child","created_at":"2026-01-02T08:25:51.475198Z","created_by":"selund"}]}
{"id":"pacabench-mls","title":"DevOps \u0026 CI/CD","description":"Set up GitHub Actions, automated testing, release workflows, and quality gates.","status":"open","priority":0,"issue_type":"epic","created_at":"2026-01-02T08:25:25.711289Z","created_by":"selund","updated_at":"2026-01-02T08:25:25.711289Z"}
{"id":"pacabench-mls.1","title":"Set up GitHub Actions CI","description":"Workflow for fmt, clippy, tests on every PR. Matrix testing for stable/nightly Rust.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:33.500085Z","created_by":"selund","updated_at":"2026-01-02T08:25:33.500085Z","dependencies":[{"issue_id":"pacabench-mls.1","depends_on_id":"pacabench-mls","type":"parent-child","created_at":"2026-01-02T08:25:33.501891Z","created_by":"selund"}]}
{"id":"pacabench-mls.2","title":"Add release automation workflow","description":"Automated releases with changelog generation and crates.io publishing.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:25:33.531116Z","created_by":"selund","updated_at":"2026-01-02T08:25:33.531116Z","dependencies":[{"issue_id":"pacabench-mls.2","depends_on_id":"pacabench-mls","type":"parent-child","created_at":"2026-01-02T08:25:33.531661Z","created_by":"selund"}]}
{"id":"pacabench-mls.3","title":"Run benchmarks in CI/CD","description":"Users can add PacaBench to GitHub Actions with pass/fail thresholds and JSON output.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:25:33.560098Z","created_by":"selund","updated_at":"2026-01-02T08:25:33.560098Z","dependencies":[{"issue_id":"pacabench-mls.3","depends_on_id":"pacabench-mls","type":"parent-child","created_at":"2026-01-02T08:25:33.560651Z","created_by":"selund"}]}
{"id":"pacabench-mls.3.1","title":"Add --threshold flag for pass/fail exit codes","description":"pacabench run --threshold 0.8 exits with code 1 if accuracy \u003c 80%. Enables CI gates.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:57.066175Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.066175Z","dependencies":[{"issue_id":"pacabench-mls.3.1","depends_on_id":"pacabench-mls.3","type":"parent-child","created_at":"2026-01-02T08:28:57.066657Z","created_by":"selund"}]}
{"id":"pacabench-mls.3.2","title":"Create GitHub Actions workflow example","description":"Example .github/workflows/benchmark.yml that runs pacabench on PR, caches datasets.","status":"open","priority":0,"issue_type":"task","created_at":"2026-01-02T08:28:57.092526Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.092526Z","dependencies":[{"issue_id":"pacabench-mls.3.2","depends_on_id":"pacabench-mls.3","type":"parent-child","created_at":"2026-01-02T08:28:57.093019Z","created_by":"selund"}]}
{"id":"pacabench-mls.3.3","title":"Add JSON output mode for CI parsing","description":"pacabench run --output json prints structured results to stdout.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-02T08:28:57.120194Z","created_by":"selund","updated_at":"2026-01-02T08:28:57.120194Z","dependencies":[{"issue_id":"pacabench-mls.3.3","depends_on_id":"pacabench-mls.3","type":"parent-child","created_at":"2026-01-02T08:28:57.120643Z","created_by":"selund"}]}
